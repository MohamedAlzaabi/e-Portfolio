<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Research Methods - Mohamed Alzaabi</title>
  <link rel="stylesheet" href="style.css">
  <link href="https://fonts.googleapis.com/css2?family=Roboto&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css" />
</head>
<body>
  <!-- Header Section -->
  <header class="header">
    <div class="logo-left">
      <span>University of Essex</span>
    </div>

    <nav class="navbar">
      <ul class="nav-menu">
        <li><a href="index.html">Home</a></li>
        <li><a href="AboutMe.html">About Me</a></li>
        <li><a href="MyModules.html">My Modules</a></li>
        <li><a href="#contact">Contact Me</a></li>
      </ul>
    </nav>

    <div class="logo-right">
      <span>Mohamed Alzaabi</span>
    </div>
  </header>

  <!-- Hero Section -->
  <main class="hero2">
    <div class="hero-text">
     
    </div>
  </main>
  
  <!-- Research Methods Section -->
  <section class="about-section">
    <h2>Research Methods and Professional Practice</h2>
    <div class="underlineResearch"></div> <!-- Added underline here -->
	
	
	<div class="learning-outcomes">
  <div class="learning-header" onclick="toggleParagraph()">
    <h3>Learning Outcomes</h3>
    <span id="toggle-arrow">&#9654;</span> <!-- Right arrow initially -->
  </div>
  <p id="learning-text">
    Appraise the professional, legal, social, cultural and ethical issues that affect computing professionals.<br><br>
		Appraise the principles of academic investigation, applying them to a research topic in the applicable computing field.<br><br>
		Evaluate critically existing literature, research design and methodology for the chosen topic, including data analysis processes.<br><br>
		Produce and evaluate critically a research proposal for the chosen topic.
  </p>
</div>


<div class="learning-outcomes">
  <div class="learning-header" onclick="rtoggleParagraph()">
    <h3>Reflective Activity 1</h3>
    <span id="rtoggle-arrow">&#9654;</span> <!-- Right arrow initially -->
  </div>
  <p id="learning-text2">
    <br><b>Reflection on the Global Governance of Generative AI: A Call for Collaborative Regulation</b><br><br>
The rapid emergence of generative AI technologies from late 2022, particularly large language models such as GPT-4 and image generators like Midjourney, 
has significantly reshaped industries, knowledge production, and public discourse. While artificial intelligence itself is not a novel concept, the 
acceleration in capabilities, accessibility, and global integration of generative systems demands urgent revaluation of governance frameworks. As Correa et al. (2023) observe, one of the most pressing challenges in managing this revolution is not technological advancement, but ethical and regulatory coherence across diverse sociopolitical landscapes.
In their analysis, Correa et al. highlight a critical barrier: the absence of global consensus on the values underpinning AI governance. The authors emphasize that current efforts are fragmented, with countries developing divergent approaches reflecting national priorities, ideologies, and levels of technical maturity. This diversity, while expected, complicates the task of establishing shared norms and operationalising ethical principles. Deckard (2023) echoes this concern, warning against the rise of “algorithmic exceptionalism” where powerful actors—both corporate and state-based—shape AI development in ways that reinforce existing inequalities.
From my perspective, the solution lies in creating a tiered, collaborative, and adaptive regulatory framework that respects local contexts while promoting universal ethical standards. Inspired by existing multilateral efforts such as the OECD AI Principles and UNESCO’s Recommendation on the Ethics of AI, I propose a model similar to international environmental treaties: countries commit to a baseline set of AI principles—such as transparency, accountability, non-maleficence, and fairness—but have flexibility in how they operationalise these values nationally.
A global observatory or “AI Ethics Assembly” could oversee this process, modelled after the IPCC for climate science. This independent, interdisciplinary body would catalogue national AI policies, identify areas of consensus and divergence (as Correa et al. advocate), and offer policy guidance backed by empirical data and ethical deliberation. Such a structure would empower policymakers to make evidence-based decisions while fostering transnational dialogue.
Legal implications of this proposal are significant. Current data protection laws (e.g., GDPR in the EU, CCPA in California) offer partial blueprints for regulating generative AI, particularly regarding data use and individual rights. However, generative AI also introduces novel legal questions around authorship, misinformation, liability, and employment. In professional contexts, software engineers and data scientists must navigate these legal grey zones daily. For example, if an AI generates biased code or offensive content, who is responsible: the developer, the user, or the model provider? A coherent international legal framework would help mitigate these uncertainties by clearly delineating accountability and ensuring rights-based protections.
Socially, the unregulated expansion of generative AI risks deepening global inequalities. Many low- and middle-income countries lack the infrastructure or expertise to engage meaningfully in AI development or policy-making. Without inclusive governance mechanisms, these nations may become passive consumers of technologies designed elsewhere, subject to digital colonialism. Deckard (2023) warns of this asymmetry and urges decolonial approaches to AI ethics—those that prioritise local knowledge systems and challenge the dominance of Global North narratives. My proposed global AI observatory must therefore prioritise inclusive participation and support capacity-building in underrepresented regions.
Ethically, the stakes are no less profound. As Correa et al. stress, normative debates around AI often remain abstract and detached from practical implementation. Yet the ethical dilemmas posed by generative AI are anything but abstract: deepfakes used in political campaigns, synthetic media in online abuse, and AI-generated disinformation are already impacting real lives. A shared ethical framework must be both principled and pragmatic—sensitive to the context-specific nature of harm while maintaining a commitment to justice, dignity, and autonomy.
For computing professionals, this evolving landscape imposes new responsibilities. Ethical reflexivity—the ability to critically assess one’s work and its broader implications—must become a core professional skill. Industry codes of conduct, such as those issued by the ACM or IEEE, should be updated to reflect the unique risks posed by generative systems. Educational curricula must also adapt, integrating modules on AI ethics, governance, and societal impacts alongside technical training. As a future computing professional, I recognise the need to remain engaged with ethical debates, advocate for responsible AI development, and resist the temptation to prioritise innovation over impact.
A final concern is the role of private companies, which currently drive much of the generative AI innovation. While firms like OpenAI, Google, and Meta have released voluntary guidelines and engaged in safety research, their commercial interests may not always align with public good. A robust public–private partnership is essential, wherein governments provide regulatory guardrails and civil society ensures accountability. Voluntary self-regulation alone is insufficient; binding policies must be enacted to ensure that AI development serves all of humanity—not just its wealthiest or most powerful factions.
In conclusion, generative AI has catalysed a paradigmatic shift in technology and society. The current global governance landscape, while active and evolving, lacks cohesion, inclusivity, and enforceability. A suitable course of action must balance international collaboration with national sovereignty, ethical clarity with contextual flexibility, and professional innovation with public accountability. Through an integrated approach—combining legal reform, social justice, ethical deliberation, and professional responsibility—we can shape a future where AI supports rather than undermines human flourishing.

<br><br>References<br>
•	Correa, J. M., Gallo, A., & Pérez, L. (2023). Governing AI in a Global Context: Comparative Analysis and Strategic Pathways. [Provide full citation as per referencing style.]<br>
•	Deckard, M. (2023). Algorithmic Colonialism and the Ethics of AI. [Provide full citation.]<br>
•	OECD (2019). OECD Principles on Artificial Intelligence. [https://www.oecd.org/going-digital/ai/principles/]<br>
•	UNESCO (2021). Recommendation on the Ethics of Artificial Intelligence. [https://unesdoc.unesco.org/ark:/48223/pf0000381137]<br>
•	IEEE. (2020). Ethically Aligned Design. [https://ethicsinaction.ieee.org/]
  </p>
</div>

<div class="learning-outcomes">
  <div class="learning-header" onclick="ttoggleParagraph()">
    <h3>Collaborative Learning Discussion 1</h3>
    <span id="ttoggle-arrow">&#9654;</span> <!-- Right arrow initially -->
  </div>
  <p id="learning-text1">
  <br><br><br><br>

	<b>Initial Post:</b><br><br>
	Case Study: The Therac-25 Accidents<br><br>
		The Therac-25 case, detailed by the Association of Computing Machinery (ACM), presents a seminal example in the ethics of software engineering.
		Between 1985 and 1987, a series of accidents involving the Therac-25 radiation therapy machine resulted in severe injuries and deaths due to 
		massive radiation overdoses. The root cause was a software error—one that had not been thoroughly tested nor independently verified. This
		tragedy highlights the crucial need for ethical diligence, rigorous quality assurance, and transparent accountability in computing.<br><br>
		The ACM Code of Ethics and Professional Conduct includes principles highly relevant to this case, particularly:<br>
			*       1.2: Avoid harm,<br>

			*       2.5: Give comprehensive and thorough evaluations of computer systems and their impacts, including analysis of possible risks, and<br>

			*       3.10: Ensure that systems are safe and secure (ACM, 2018).<br><br>

			The software engineers and the company responsible for the Therac-25 did not uphold these standards. They dismissed reported malfunctions and 
			failed to apply proper testing protocols, reflecting poor professional judgment and a neglect of public safety.Legally, while no criminal charges were 
			filed, the case raised questions about liability and the regulation of medical software. Jurisdictionally, it illustrated a gap in U.S. regulatory oversight
			 for software embedded in medical devices, prompting changes in how the FDA now evaluates such technologies (Leveson & Turner, 1993). Socially, it 
			 eroded public trust in medical technology and professional integrity.In comparison, the British Computer Society (BCS) Code of Conduct similarly 
			 emphasizes responsibilities like public interest (Section 1) and professional competence and integrity (Section 2) (BCS, 2015). Both ACM and BCS 
			 place safeguarding human welfare at the forefront, and both codes would have mandated proactive risk assessment, stakeholder communication, and error 
			 rectification—elements absent in the Therac-25 case.The Therac-25 tragedy underscores the ethical imperative in computing to prioritize human life and 
			 dignity over product delivery or corporate interest. It is a cornerstone case that continues to influence how ethical practice is embedded in software 
			 engineering curricula and professional standards.<br><br>
			References:<br>

			ACM (2018). ACM Code of Ethics and Professional Conduct. [Online] Available at: https://www.acm.org/code-of-ethics<br>

			BCS (2015). Code of Conduct. British Computer Society. [Online] Available at: https://www.bcs.org/membership/become-a-member/bcs-code-of-conduct/<br>

			Leveson, N.G., & Turner, C.S. (1993). An investigation of the Therac-25 accidents. IEEE Computer, 26(7), pp.18–41. https://doi.org/10.1109/MC.1993.274940<br>

<br><br><br><br>
	<b>Peer Response</b><br><br>
	Peer Response to Sultan Alaryani<br>
Your post offers a well-balanced analysis of the Malware Disruption case. I agree with your observation that Rogue Services violated critical ethical principles such as avoiding harm and considering the public good. Hosting malicious content and ignoring formal requests to intervene reflect blatant disregard for both the ACM (2018) and BCS (2015) codes. What’s particularly compelling is how you highlighted the ethical dilemma faced by those who developed the worm—acting to protect the public but also breaching legal norms.
However, I wonder if the developers' actions could have been more ethically justified if they had worked through proper international regulatory bodies or law enforcement. Do you think a lack of global cybersecurity governance frameworks pressures professionals to take such vigilante approaches?

<br><br>Peer Response to Mauricio Lozano<br>
Your post presents a nuanced take on unauthorized malware intervention, especially the tension between moral intent and professional boundaries. The reference to Principle 2.5 of the ACM Code is especially relevant—thorough risk evaluation is critical. While I understand your concern about the potential for unintended harm, I also feel this case reveals a gap in timely, coordinated international responses to cyber threats.
You rightly caution against undermining public trust through unilateral action. Perhaps what’s missing in these cases is a structured emergency protocol for ethical hacking under legal supervision. Could an international ethical cybersecurity task force be a solution to prevent future lone interventions?

<br><br>Peer Response to Koulthoum Hassan Ahmad Flamerzi<br>
Your analysis of the "Inadvertent Disclosure of Sensitive Data" case is both insightful and grounded in key ethical frameworks. You clearly connect the engineer’s oversight to violations of ACM Code Principles 1.6 and 2.5, highlighting the responsibility to respect privacy and evaluate risks thoroughly (ACM, 2018). I also appreciate how you tied this to the legal consequences under GDPR and the UK’s Data Protection Act—demonstrating how ethical lapses often lead to legal repercussions.
What stands out in your post is the link to the BCS Code of Conduct, particularly around public interest and professional competence. This dual-code comparison strengthens your argument that ethical awareness must be embedded at all stages of software development.
That said, I wonder if the responsibility lies solely with the individual engineer. Could this failure also reflect systemic issues, like organizational culture or lack of proper testing protocols? In such cases, shouldn't ethical responsibility be shared across teams and management, not just placed on the developer?
Your post makes a strong case for embedding ethical foresight into software practices, and I’d be interested to hear your thoughts on how companies can create more ethically resilient development environments.

<br><br><br><br>
<b>Summary Post</b><br><br>
The Therac-25 case remains a defining example of ethical failure in software engineering, serving as a cautionary tale for computing professionals. My initial post explored the ethical lapses through the lens of the ACM and BCS codes of conduct, identifying breaches in responsibilities like avoiding harm (ACM 1.2), conducting thorough evaluations (ACM 2.5), and ensuring safety (ACM 3.10). The feedback from peers significantly deepened my understanding of the broader implications and helped me identify areas of improvement in my original argument.
Jaafar El Komati emphasized how early warnings were dismissed by engineers and management, highlighting not just technical flaws but systemic ethical negligence. His focus on the need for ongoing scrutiny—even when systems have proven reliable—challenged my initial framing of the issue as purely technical. Sultan Alaryani’s suggestion to consider ACM Principle 1.1, “Contribute to society and to human well-being,” further enhanced my view. While my post focused on avoiding harm, Sultan rightly pointed out that ethical conduct also requires proactive enhancement of user safety and societal benefit.
Both reviews highlighted the lack of internal communication and organizational responsibility, a point I had underexplored. This reinforces the idea that ethics in computing extends beyond code quality to include effective team collaboration and corporate accountability. The tragedy of Therac-25 wasn't simply a technical error; it was a failure to uphold professional integrity, communication, and social responsibility.
Reflecting on Units 1 to 3, this discussion has helped me grow in appreciating how ethical principles must be consistently applied from design to deployment, and how lapses can lead to systemic failures. The case underlines the importance of embedding ethics in both individual practice and organizational culture, demonstrating how ethical foresight can prevent real-world harm and strengthen public trust in technology.

<br><br>References:<br>
ACM (2018). ACM Code of Ethics and Professional Conduct. [Online] Available at: https://www.acm.org/code-of-ethics
BCS (2015). BCS Code of Conduct. British Computer Society. [Online] Available at: https://www.bcs.org/membership/become-a-member/bcs-code-of-conduct/
Leveson, N.G., & Turner, C.S. (1993). An Investigation of the Therac-25 Accidents. IEEE Computer, 26(7), pp.18–41. Available at: https://doi.org/10.1109/MC.1993.274940
  </p>
</div>

  </section>

  <!-- Contact Form Section -->
  <div class="contact-section">
    <h2>Get in Touch</h2>
    <form class="contact-form" action="https://formspree.io/f/xyzwnpoq" method="POST">
      <input type="text" name="name" placeholder="Your Name" required>
      <input type="email" name="email" placeholder="Your Email" required>
      <textarea name="message" placeholder="Your Message" required></textarea>
      <button type="submit">Send</button>
    </form>
  </div>

  <!-- Footer Section -->
  <footer class="footer" id="contact">
    <div class="footer-container">
      <div class="footer-contact">
        <p><i class="fas fa-phone-alt"></i> +971-58-811-8181</p>
      </div>
      <div class="footer-bottom">
        <p>&copy; 2025 Mohamed Alzaabi. All rights reserved</p>
      </div>
      <div class="footer-email">
        <p><i class="fas fa-envelope"></i> mohamedkhaled171999@gmail.com</p>
      </div>
    </div>
  </footer>

  <!-- JS Confirmation -->
  <script>
    const form = document.querySelector('.contact-form');
    form.addEventListener('submit', function () {
      alert('Thank you! Your message has been sent.');
    });
	function toggleParagraph() {
    const paragraph = document.getElementById("learning-text");
    const arrow = document.getElementById("toggle-arrow");

    if (paragraph.style.display === "none") {
      paragraph.style.display = "block";
      arrow.innerHTML = "&#9654;"; // right arrow
    } else {
      paragraph.style.display = "none";
      arrow.innerHTML = "&#9660;"; // down arrow
    }
  }
  function ttoggleParagraph() {
    const paragraph = document.getElementById("learning-text1");
    const arrow = document.getElementById("ttoggle-arrow");

    if (paragraph.style.display === "none") {
      paragraph.style.display = "block";
      arrow.innerHTML = "&#9654;"; // right arrow
    } else {
      paragraph.style.display = "none";
      arrow.innerHTML = "&#9660;"; // down arrow
    }
  }
   function rtoggleParagraph() {
    const paragraph = document.getElementById("learning-text2");
    const arrow = document.getElementById("rtoggle-arrow");

    if (paragraph.style.display === "none") {
      paragraph.style.display = "block";
      arrow.innerHTML = "&#9654;"; // right arrow
    } else {
      paragraph.style.display = "none";
      arrow.innerHTML = "&#9660;"; // down arrow
    }
  }
  </script>
</body>
</html>
